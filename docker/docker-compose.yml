services:
  # Infrastructure Services
  postgres:
    image: pgvector/pgvector:pg17
    shm_size: 4gb
    container_name: omni-postgres
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - omni-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: omni-redis
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    networks:
      - omni-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Database Migrator
  migrator:
    build:
      context: ..
      dockerfile: services/migrations/Dockerfile
    image: omni-migrator
    container_name: omni-migrator
    environment:
      - DATABASE_URL=${DATABASE_URL}
    networks:
      - omni-network
    depends_on:
      postgres:
        condition: service_healthy
    restart: "no"

  # Core Services
  searcher:
    build:
      context: ..
      dockerfile: services/searcher/Dockerfile
    image: omni-searcher
    container_name: omni-searcher
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - DB_MAX_CONNECTIONS=${DB_MAX_CONNECTIONS:-10}
      - DB_ACQUIRE_TIMEOUT_SECONDS=${DB_ACQUIRE_TIMEOUT_SECONDS:-3}
      - REDIS_URL=${REDIS_URL}
      - RUST_LOG=${RUST_LOG}
      - PORT=${SEARCHER_PORT}
      - AI_SERVICE_URL=${AI_SERVICE_URL}
      - TYPO_TOLERANCE_ENABLED=${TYPO_TOLERANCE_ENABLED:-true}
      - TYPO_TOLERANCE_MAX_DISTANCE=${TYPO_TOLERANCE_MAX_DISTANCE:-2}
      - TYPO_TOLERANCE_MIN_WORD_LENGTH=${TYPO_TOLERANCE_MIN_WORD_LENGTH:-4}
    networks:
      - omni-network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      migrator:
        condition: service_completed_successfully
    restart: unless-stopped

  indexer:
    build:
      context: ..
      dockerfile: services/indexer/Dockerfile
    image: omni-indexer
    container_name: omni-indexer
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - DB_MAX_CONNECTIONS=${DB_MAX_CONNECTIONS:-10}
      - DB_ACQUIRE_TIMEOUT_SECONDS=${DB_ACQUIRE_TIMEOUT_SECONDS:-3}
      - REDIS_URL=${REDIS_URL}
      - RUST_LOG=${RUST_LOG}
      - PORT=${INDEXER_PORT}
      - AI_SERVICE_URL=${AI_SERVICE_URL}
      - ENCRYPTION_KEY=${ENCRYPTION_KEY}
      - ENCRYPTION_SALT=${ENCRYPTION_SALT}
    networks:
      - omni-network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      migrator:
        condition: service_completed_successfully
    restart: unless-stopped

  ai:
    # build:
    #   context: ../services/ai
    #   dockerfile: Dockerfile.gpu
    image: ghcr.io/omnihq/omni-ai:latest
    container_name: omni-ai
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - DB_MAX_CONNECTIONS=${DB_MAX_CONNECTIONS:-10}
      - DB_ACQUIRE_TIMEOUT_SECONDS=${DB_ACQUIRE_TIMEOUT_SECONDS:-3}
      - REDIS_URL=${REDIS_URL}
      - RUST_LOG=${RUST_LOG}
      - PORT=${AI_SERVICE_PORT}
      - MODEL_PATH=${MODEL_PATH}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL}
      - EMBEDDING_DIMENSIONS=${EMBEDDING_DIMENSIONS}
      - LLM_PROVIDER=${LLM_PROVIDER:-vllm}
      - VLLM_URL=${VLLM_URL:-http://vllm:8000}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - ANTHROPIC_MODEL=${ANTHROPIC_MODEL:-claude-3-5-sonnet-20241022}
      - ANTHROPIC_MAX_TOKENS=${ANTHROPIC_MAX_TOKENS:-4096}
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
      - AI_WORKERS=${AI_WORKERS:-1}  # Number of uvicorn workers
      - JINA_API_KEY=${JINA_API_KEY}
      - EMBEDDING_PROVIDER=${EMBEDDING_PROVIDER}
    networks:
      - omni-network
    volumes:
      - ai_models:/models
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      migrator:
        condition: service_completed_successfully
    restart: unless-stopped

  # vLLM Service for LLM inference (optional - only when using vLLM provider)
  vllm:
    image: vllm/vllm-openai:latest
    container_name: omni-vllm
    environment:
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
    command: >
      --model ${VLLM_MODEL}
      --dtype ${VLLM_DTYPE:-auto}
      --api-key ${VLLM_API_KEY}
      --port ${VLLM_PORT}
      --host 0.0.0.0
      --max-model-len ${VLLM_MAX_MODEL_LEN}
    networks:
      - omni-network
    volumes:
      - vllm_models:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    profiles:
      - vllm  # Only start when vllm profile is active

  # Connector Services
  google-connector:
    build:
      context: ..
      dockerfile: connectors/google/Dockerfile
    image: omni-google-connector
    container_name: omni-google-connector
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - RUST_LOG=${RUST_LOG}
      - PORT=${GOOGLE_CONNECTOR_PORT}
      - AI_SERVICE_URL=${AI_SERVICE_URL}
      - GOOGLE_CLIENT_ID=${GOOGLE_CLIENT_ID}
      - GOOGLE_CLIENT_SECRET=${GOOGLE_CLIENT_SECRET}
      - GOOGLE_REDIRECT_URI=${GOOGLE_REDIRECT_URI}
      - GOOGLE_SYNC_INTERVAL_SECONDS=${GOOGLE_SYNC_INTERVAL_SECONDS}
      - GOOGLE_MAX_AGE_DAYS=${GOOGLE_MAX_AGE_DAYS:-730}
      - GOOGLE_WEBHOOK_URL=${GOOGLE_WEBHOOK_URL}
      - WEBHOOK_RENEWAL_CHECK_INTERVAL_SECONDS=${WEBHOOK_RENEWAL_CHECK_INTERVAL_SECONDS:-3600}
      - ENCRYPTION_KEY=${ENCRYPTION_KEY}
      - ENCRYPTION_SALT=${ENCRYPTION_SALT}
    networks:
      - omni-network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      migrator:
        condition: service_completed_successfully
    restart: unless-stopped

  slack-connector:
    build:
      context: ..
      dockerfile: connectors/slack/Dockerfile
    image: omni-slack-connector
    container_name: omni-slack-connector
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - DB_MAX_CONNECTIONS=${DB_MAX_CONNECTIONS:-10}
      - DB_ACQUIRE_TIMEOUT_SECONDS=${DB_ACQUIRE_TIMEOUT_SECONDS:-3}
      - REDIS_URL=${REDIS_URL}
      - RUST_LOG=${RUST_LOG}
      - PORT=${SLACK_CONNECTOR_PORT}
      - SLACK_BOT_TOKEN=${SLACK_BOT_TOKEN}
    networks:
      - omni-network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      migrator:
        condition: service_completed_successfully
    restart: unless-stopped

  atlassian-connector:
    build:
      context: ..
      dockerfile: connectors/atlassian/Dockerfile
    image: omni-atlassian-connector
    container_name: omni-atlassian-connector
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - DB_MAX_CONNECTIONS=${DB_MAX_CONNECTIONS:-10}
      - DB_ACQUIRE_TIMEOUT_SECONDS=${DB_ACQUIRE_TIMEOUT_SECONDS:-3}
      - REDIS_URL=${REDIS_URL}
      - RUST_LOG=${RUST_LOG}
      - PORT=${ATLASSIAN_CONNECTOR_PORT}
      - ATLASSIAN_BASE_URL=${ATLASSIAN_BASE_URL}
      - ATLASSIAN_USER_EMAIL=${ATLASSIAN_USER_EMAIL}
      - ATLASSIAN_API_TOKEN=${ATLASSIAN_API_TOKEN}
    networks:
      - omni-network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      migrator:
        condition: service_completed_successfully
    restart: unless-stopped

  # Web Application (SvelteKit frontend + backend)
  web:
    build:
      context: ../web
    image: omni-web
    container_name: omni-web
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - DB_MAX_CONNECTIONS=${DB_MAX_CONNECTIONS:-10}
      - DB_ACQUIRE_TIMEOUT_SECONDS=${DB_ACQUIRE_TIMEOUT_SECONDS:-3}
      - REDIS_URL=${REDIS_URL}
      - SEARCHER_URL=${SEARCHER_URL}
      - INDEXER_URL=${INDEXER_URL}
      - AI_SERVICE_URL=${AI_SERVICE_URL}
      - GOOGLE_CONNECTOR_URL=${GOOGLE_CONNECTOR_URL}
      - SESSION_SECRET=${SESSION_SECRET}
      - SESSION_COOKIE_NAME=${SESSION_COOKIE_NAME}
      - SESSION_DURATION_DAYS=${SESSION_DURATION_DAYS}
      - APP_URL=${APP_URL}
      - GOOGLE_CLIENT_ID=${GOOGLE_CLIENT_ID}
      - GOOGLE_CLIENT_SECRET=${GOOGLE_CLIENT_SECRET}
      - GOOGLE_REDIRECT_URI=${GOOGLE_REDIRECT_URI}
      - EMAIL_PROVIDER=${EMAIL_PROVIDER:-resend}
      - RESEND_API_KEY=${RESEND_API_KEY}
      - EMAIL_FROM=${EMAIL_FROM:-Clio <noreply@yourdomain.com>}
      - EMAIL_HOST=${EMAIL_HOST}
      - EMAIL_PORT=${EMAIL_PORT}
      - EMAIL_USER=${EMAIL_USER}
      - EMAIL_PASSWORD=${EMAIL_PASSWORD}
      - EMAIL_SECURE=${EMAIL_SECURE}
      - AI_ANSWER_ENABLED=${AI_ANSWER_ENABLED}
    networks:
      - omni-network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      migrator:
        condition: service_completed_successfully
      searcher:
        condition: service_started
      indexer:
        condition: service_started
      ai:
        condition: service_started
    restart: unless-stopped

  # Load Balancer / Reverse Proxy
  caddy:
    image: caddy:2-alpine
    container_name: omni-caddy
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ../Caddyfile:/etc/caddy/Caddyfile
      - caddy_data:/data
      - caddy_config:/config
    networks:
      - omni-network
    depends_on:
      - web
    restart: unless-stopped

networks:
  omni-network:
    driver: bridge

volumes:
  postgres_data:
    name: omni-postgres-data
  redis_data:
    name: omni-redis-data
  ai_models:
    name: omni-ai-models
  vllm_models:
    name: omni-vllm-models
  caddy_data:
    name: omni-caddy-data
  caddy_config:
    name: omni-caddy-config
